# ğŸ¥ Medical Assistance â€“ AI-Powered Healthcare Chatbot

ğŸ”— **Live Application:**  
https://medicalassistance-123.streamlit.app/

---

## ğŸ“Œ Overview

Medical Assistance is a full-stack AI-powered healthcare chatbot that provides general medical information, medication guidance, and responses to common health-related queries.

The application is built using:

- **FastAPI** â€“ Backend API service
- **Streamlit** â€“ Interactive frontend interface
- **LangChain** â€“ Prompt orchestration
- **LLM Integration** â€“ AI-generated medical responses

This project demonstrates full-stack AI deployment with a cloud-hosted backend and frontend.

---

## ğŸ—ï¸ Architecture
```
User (Browser)
    â†“
Streamlit Frontend (Public URL)
    â†“
FastAPI Backend (Render Cloud)
    â†“
LLM Service (via LangChain)
```


### Deployment Stack

- **Backend Hosted On:** Render  
- **Frontend Hosted On:** Streamlit Community Cloud  

---

## ğŸ“‚ Project Structure
```
Medical_Assistance/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ backend.py
â”‚ â”œâ”€â”€ llm_service.py
â”‚ â”œâ”€â”€ memory_store.py
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ app.py
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```


---

## âš™ï¸ Features

- ğŸ’Š Medication information
- ğŸ©º General health query support
- ğŸ§  AI-based conversational responses
- ğŸ’¬ Chat-style interface
- â˜ï¸ Fully deployed public application
- ğŸ” Environment variable support for API keys
- ğŸŒ REST API backend with interactive Swagger docs

---

## ğŸ–¥ï¸ Backend (FastAPI)

### Main Entry Point

`backend/backend.py`

The FastAPI app exposes endpoints such as:
GET /
POST /ask


Swagger Documentation (Backend API): https://medical-assistance-h1go.onrender.com/docs


---

## ğŸ¨ Frontend (Streamlit)

### Main File

`frontend/app.py`

The frontend:

- Accepts user input
- Sends requests to the backend API
- Displays AI-generated responses

Backend URL configured in production:

```python
BACKEND_URL = "https://medical-assistance-h1go.onrender.com/ask"
```
ğŸš€ Local Setup Guide
```
1ï¸âƒ£ Clone the Repository
git clone https://github.com/kshivayadav/Medical_Assistance.git
cd Medical_Assistance

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate   # Windows

3ï¸âƒ£ Install Backend Dependencies
pip install -r backend/requirements.txt

4ï¸âƒ£ Install Frontend Dependencies
pip install -r frontend/requirements.txt

5ï¸âƒ£ Run Backend
uvicorn backend.backend:app --reload
Backend runs at:
http://127.0.0.1:8000

6ï¸âƒ£ Run Frontend
streamlit run frontend/app.py
Frontend runs at: 
http://localhost:8501

ğŸ” Environment Variables

Create a .env file in the root directory:
GROQ_API_KEY=your_api_key_here
```

In production:

Add environment variables inside Render dashboard

Add secrets inside Streamlit Cloud settings


â˜ï¸ Deployment Details
Backend Deployment (Render)

Build Command:
```
pip install -r backend/requirements.txt
```

Start Command:
```
uvicorn backend.backend:app --host 0.0.0.0 --port 10000
```
Frontend Deployment (Streamlit Cloud)

Repository connected via GitHub

Main file path:
```
frontend/app.py
```

### ğŸ› ï¸ Tech Stack

Python 3.x

FastAPI

Uvicorn

Streamlit

LangChain

OpenAI API (LLM Integration)

Render Cloud

Streamlit Community Cloud

### âš ï¸ Disclaimer

This application provides AI-generated general medical information for educational purposes only.

It does not replace professional medical diagnosis or treatment.
Always consult a qualified healthcare provider for medical concerns.

### ğŸ“ˆ Future Improvements

User authentication

Conversation history persistence (database integration)

Role-based medical assistant modes

Improved prompt engineering

Rate limiting and security hardening

Docker containerization

CI/CD pipeline integration

### ğŸ‘¨â€ğŸ’» Author

K Shiva Kumar
AI / ML Engineer | Full-Stack AI Developer

### â­ If You Like This Project

Consider starring the repository to support development.
